# ğŸ§  context-aware-support-llm

This repository contains the implementation of **Customer Support Automation using LLMs and Intelligent Context Management**.  
It is a **Retrieval-Augmented Generation (RAG)** system that automates customer support by combining **Large Language Models (LLMs)** with **intelligent context management** to deliver context-aware answers using company-specific documents.

## ğŸš€ Features
- ğŸ’¬ Natural-language question answering  
- ğŸ“„ Automatic document ingestion and chunking  
- ğŸ” Semantic search using FAISS and SentenceTransformers  
- ğŸ§  Context-aware response generation with a Small Language Model (SLM)  
- âš™ï¸ RESTful API built using FastAPI

## âš™ï¸ Setup & Execution
```bash
pip install -r requirements.txt
python indexer.py
uvicorn rag_server:app --reload --port 8000

Technologies Used:

Python, FastAPI, Uvicorn
FAISS, SentenceTransformers
dotenv, pypdf, tiktoken

ğŸ’¡ Future Enhancements

Connect to the companyâ€™s real SLM endpoint

Add contextual memory and analytics dashboard

Integrate with customer chat or support platforms
